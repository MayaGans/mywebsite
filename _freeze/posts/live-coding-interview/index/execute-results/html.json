{
  "hash": "41e8872b563dc9b683a40cfcf7cc6fc6",
  "result": {
    "markdown": "---\ntitle: \"My First Live Coding Interview\"\nauthor: \"Maya Gans\"\ndate: '2019-08-27'\ndescription: \"I tanked my first live coding interview but that still made me want to find answers to all their questions\"\ncategories: [R]\nimage: \"featured.png\"\n---\n\n\nYesterday I interviewed for a position maintaining and creating ShinyApps. To call that a JOB is crazy to me. I love developing reactive web applications, the fact that you can get paid to do that is still mind blowing. I'm realizing that having fun at work is actually a possibility!\n\nThat said, the data scientist position usually includes a live coding portion. I went into it trying to treat my first one as practice, but every second I didn't spend typing spanned an eternity. It was horrifying... but thinking about how to solve these questions was also kind of really fun? \n\nI'm fairly certain I won't get the job. But I'm also certain it was an experience to learn and grow. The interview was so intense that it was pretty easy to recall the questions almost verbatim. I wanted to explore the questions again on my own with no pressure. And I'd love input on how to answer these more elegantly!\n\n:::twitter\nBefore we begin, I've updated this post to include asides provided from the wonderful world of `#rstats` twitter. If you have any suggestions on tidying the code feel free to contact me or [submit a PR to my blog repo!](https://github.com/MayaGans/BayesianBabe/tree/master/content/post/2019-08-27-live-coding-interview)\n:::\n\n## Question 1\n\nCreate a for loop for n iterations where every third iteration prints \"buzz\" and every fifth iteration prints \"fizz\". Every combination prints \"buzz-fizz\". Print the iterator for all other values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn = 30\n\nfor (i in 1:n) {\n  if (i %% 15 == 0) {\n    print(paste(i,\"buzz-fizz\"))\n      } else if (i %% 3 == 0) {\n        print(paste(i, \"buzz\"))\n      } else if (i %% 5 == 0) {\n        print(paste(i, \"fizz\"))\n      }\n  print(i)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n[1] 2\n[1] \"3 buzz\"\n[1] 3\n[1] 4\n[1] \"5 fizz\"\n[1] 5\n[1] \"6 buzz\"\n[1] 6\n[1] 7\n[1] 8\n[1] \"9 buzz\"\n[1] 9\n[1] \"10 fizz\"\n[1] 10\n[1] 11\n[1] \"12 buzz\"\n[1] 12\n[1] 13\n[1] 14\n[1] \"15 buzz-fizz\"\n[1] 15\n[1] 16\n[1] 17\n[1] \"18 buzz\"\n[1] 18\n[1] 19\n[1] \"20 fizz\"\n[1] 20\n[1] \"21 buzz\"\n[1] 21\n[1] 22\n[1] 23\n[1] \"24 buzz\"\n[1] 24\n[1] \"25 fizz\"\n[1] 25\n[1] 26\n[1] \"27 buzz\"\n[1] 27\n[1] 28\n[1] 29\n[1] \"30 buzz-fizz\"\n[1] 30\n```\n:::\n:::\n\n\nMy first attempt answering the question revealed a gap in my mental model. I first attempted to construct the loop using an if statement with logical arguments in the same order as the question: `(i %% 3 == 0)`, then `(i %% 5 == 0)` and lastly `(i %% 15 == 0)`. I was operating under the idea that the arguments within a loop are circular. However, these arguments are inside an `if` statement, not the loop itself, so of course order matters! By putting `(i %% 15 == 0)` first you ensure the numbers divisible by both 3 and 5 are assigned to `buzz-feed` prior to `buzz` or `feed` assignment.\n\n:::twitter\n## The R Way\nR's strength is in dealing with vectors, so leverage that in the approach! [Jon Harmon](https://twitter.com/JonTheGeek) suggested a better approach for this problem.\n\n::: {.cell}\n\n```{.r .cell-code}\n    n = 15\n    dplyr::tibble(\n    iteration = seq_len(n),\n    output = dplyr::case_when(\n    iteration %% 15 == 0 ~ \"buzz-fizz\", \n    iteration %% 3 == 0 ~ \"buzz\",\n    iteration %% 5 == 0 ~ \"fizz\",\n    TRUE ~ as.character(iteration)\n  )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 x 2\n   iteration output   \n       <int> <chr>    \n 1         1 1        \n 2         2 2        \n 3         3 buzz     \n 4         4 4        \n 5         5 fizz     \n 6         6 buzz     \n 7         7 7        \n 8         8 8        \n 9         9 buzz     \n10        10 fizz     \n11        11 11       \n12        12 buzz     \n13        13 13       \n14        14 14       \n15        15 buzz-fizz\n```\n:::\n:::\n\nIn fact, this same question is the first example within the `dplyr::case_when` documentation!\n:::\n\n## Question 2\n\n### Summarize the diamonds data set\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(ggplot2::diamonds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     carat               cut        color        clarity          depth      \n Min.   :0.2000   Fair     : 1610   D: 6775   SI1    :13065   Min.   :43.00  \n 1st Qu.:0.4000   Good     : 4906   E: 9797   VS2    :12258   1st Qu.:61.00  \n Median :0.7000   Very Good:12082   F: 9542   SI2    : 9194   Median :61.80  \n Mean   :0.7979   Premium  :13791   G:11292   VS1    : 8171   Mean   :61.75  \n 3rd Qu.:1.0400   Ideal    :21551   H: 8304   VVS2   : 5066   3rd Qu.:62.50  \n Max.   :5.0100                     I: 5422   VVS1   : 3655   Max.   :79.00  \n                                    J: 2808   (Other): 2531                  \n     table           price             x                y         \n Min.   :43.00   Min.   :  326   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:56.00   1st Qu.:  950   1st Qu.: 4.710   1st Qu.: 4.720  \n Median :57.00   Median : 2401   Median : 5.700   Median : 5.710  \n Mean   :57.46   Mean   : 3933   Mean   : 5.731   Mean   : 5.735  \n 3rd Qu.:59.00   3rd Qu.: 5324   3rd Qu.: 6.540   3rd Qu.: 6.540  \n Max.   :95.00   Max.   :18823   Max.   :10.740   Max.   :58.900  \n                                                                  \n       z         \n Min.   : 0.000  \n 1st Qu.: 2.910  \n Median : 3.530  \n Mean   : 3.539  \n 3rd Qu.: 4.040  \n Max.   :31.800  \n                 \n```\n:::\n:::\n\n\nIn an attempt to over-complicate this question and to flex my `tidyverse` skills, I was quick to type `diamonds %>% summarise(mean =....)` but the instructor asked \"Are you going to write the name of every column?\" I panicked. I skipped this question finally remembered the `summary` function. (Clearly, base R functions are currently in the dark recesses of my mind. Use it or lose it...)\n\n#### Find the maximum diamond price\n\n::: {.cell}\n\n```{.r .cell-code}\ndiamonds %>%\n  filter(price == max(price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 10\n  carat cut     color clarity depth table price     x     y     z\n  <dbl> <ord>   <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n1  2.29 Premium I     VS2      60.8    60 18823   8.5  8.47  5.16\n```\n:::\n:::\n\n\nI was quick to type `max(diamonds$price)` and smugly said 'Done!' The interviewer responded, okay but I wanted to know everything else about that diamond. This meant I needed to print the whole row. I'm not sure the function I'm using is the most efficient, but I like it?\n\n#### Calculate the mean, median, standard deviation of the price for each diamond cut\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot2::diamonds %>%\n  group_by(cut) %>%\n  summarise(mean = mean(price),\n            med = median(price),\n            std = sd(price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 4\n  cut        mean   med   std\n  <ord>     <dbl> <dbl> <dbl>\n1 Fair      4359. 3282  3560.\n2 Good      3929. 3050. 3682.\n3 Very Good 3982. 2648  3936.\n4 Premium   4584. 3185  4349.\n5 Ideal     3458. 1810  3808.\n```\n:::\n:::\n\nFinally a question I felt comfortable answering! My TidyBlocks focus of the past couple months made me feel quite comfortable with this one.\n\n## Question 3\nUsing the MTCars data set, create a linear model to see the affect of mpg on disp and explain the output of the model \n\n::: {.cell}\n\n```{.r .cell-code}\nm.1 <- lm(mtcars$mpg ~ mtcars$disp)\nsummary(m.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = mtcars$mpg ~ mtcars$disp)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8922 -2.2022 -0.9631  1.6272  7.2305 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 29.599855   1.229720  24.070  < 2e-16 ***\nmtcars$disp -0.041215   0.004712  -8.747 9.38e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.251 on 30 degrees of freedom\nMultiple R-squared:  0.7183,\tAdjusted R-squared:  0.709 \nF-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10\n```\n:::\n:::\n\n\nHonestly, I could write this simple code from memory, but what I said as an explanation is an embarrassing blur. I think I can only attribute floundering over the output of a linear model with a single predictor to nerves. \n\nI'm taking the time here to break the output of the model summary down line for line because every aspiring data scientist should be so comfortable the `lm` output that even nerves shouldn't matter.\n\n* `The call` is an R feature that shows the function and its parameters\n* `The residuals` are the difference between the model predicted and actual values of `disp`\n* `The coefficents` are the weights that minimize the sum of the square of the errors\n    * Since `mpg` never equals zero, there's no intrinsic meaning to the intercept\n    * The negative sign of `disp` means as `mpg` increases, `disp` decreases\n* `Residual standard error` is the standard deviation of the error where the SD is the square root of the variance \n* `Multiple R squared` is a measurement of how well the model fits your data\n    * An R = 0.7 is pretty good?\n* `Adjusted R squared` takes the amount of variables you add to the model into account as that will inevitably produce a better fit. Because we only have one predictor this number is only very slightly different from our R squared.\n* `F-Statistic` a global statistic to check if at least one coefficient is non-zero.\n\n\n## Question 4\nCreate a function that separates a list into two lists, one of unique values and the second containing the duplicates\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nmy_list <- list(round(runif(100, min=0, max=100)), 1)\n\nseperated <- function(input) {\n  dup <- unique(input[[1]][duplicated(input[[1]])])\n  unq <- input[[1]][!input[[1]] %in% input[[1]][duplicated(input[[1]])]]\n  return(list(dup, unq))\n}\n\nseperated(my_list)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n [1] 46 94 91 74 39 83 64 97  4 26 51 68 98 69 14 72  1 38  0 78 56  9 21 93 33\n[26] 52 62\n\n[[2]]\n [1] 29 13 66 71 12 47 90 99 95  8 45 84 81 61 44 43 96 89 35 40 75 17 76 57 85\n[26] 19 27 24 22 48 20 58 16 36 65 23 31 67 73\n```\n:::\n:::\n\n\nTo get there, I made a dummy data set to play with, a list with 6 numbers, only one of which is a duplicate. This helped to highlight the workflow (1) find the duplicates for the first list, then (2) find the unique values, but remove the duplicates\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- list(c(1,2,3,4,5,3))\n\n# find duplicates\ntest[[1]][duplicated(test[[1]])]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3\n```\n:::\n\n```{.r .cell-code}\n# I thought of another case -\n# if we have muliple duplicates (three 3s)\n# we need to wrap this function in unique()\ntest2 <- list(c(1,2,3,4,5,3,3))\nunique(test2[[1]][duplicated(test2[[1]])])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3\n```\n:::\n\n```{.r .cell-code}\n# remove duplicates from unique values\ntest[[1]][!test[[1]] %in% test[[1]][duplicated(test[[1]])]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 4 5\n```\n:::\n:::\n\n\nObtaining the data from inside a list, especially nested lists, is a skill I know I need to build. This answer does not look elegant to me but it gets the job done? I'm going to play with \"better\", cleaner solutions.\n\n## Summary\n\nI left the interview feeling exhausted and deflated. I found myself asking: *if I can't answer these questions, what am I doing trying to become a data scientist?* But now that I've spent a day to reflect, the interview was an incredible learning experience. It pinpointed concrete areas where I can grow and I honestly had fun thinking about these problems. I'm not sure I'll ever perform smoothly under pressure, but at the very least I now have a function to separate duplicates from unique values!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}